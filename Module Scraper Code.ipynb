{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e7b250",
   "metadata": {},
   "source": [
    "# Module Information Scraper\n",
    "This code is to scrape assessment details from UCD module-by-module. From there, we can find out how vulnerable UCD is to ChatGPT and other similar AI helpers. First we will need to import some packages to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ddfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pathlib as Path\n",
    "import html5lib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b58396",
   "metadata": {},
   "source": [
    "Next we will need to set the path to the datasets that we will use. This currently pulls in a specific file, that of MODULES.csv, which has all collected module information for the school of Engineering and Architecture. However, this could easily be changed to analyze sub-schools or other schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b1d91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Module</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSCY10060</td>\n",
       "      <td>Energy, Climate Change &amp; Policy</td>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EEEN10010</td>\n",
       "      <td>Electronic and Electrical Engineering I</td>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EEEN10020</td>\n",
       "      <td>Robotics Design Project</td>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EEEN20010</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EEEN20020</td>\n",
       "      <td>Electrical and Electronic Circuits</td>\n",
       "      <td>EEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>MEEN50050</td>\n",
       "      <td>Creative Thinking &amp; Innovation</td>\n",
       "      <td>MME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>MEEN50060</td>\n",
       "      <td>Research Techniques Space Eng</td>\n",
       "      <td>MME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>MEEN50070</td>\n",
       "      <td>Industrial Research I</td>\n",
       "      <td>MME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>MEEN50080</td>\n",
       "      <td>Industrial Research II</td>\n",
       "      <td>MME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>MEEN50090</td>\n",
       "      <td>Industrial Research III</td>\n",
       "      <td>MME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Code                                   Module School\n",
       "0    DSCY10060          Energy, Climate Change & Policy    EEE\n",
       "1    EEEN10010  Electronic and Electrical Engineering I    EEE\n",
       "2    EEEN10020                  Robotics Design Project    EEE\n",
       "3    EEEN20010                     Computer Engineering    EEE\n",
       "4    EEEN20020       Electrical and Electronic Circuits    EEE\n",
       "..         ...                                      ...    ...\n",
       "519  MEEN50050           Creative Thinking & Innovation    MME\n",
       "520  MEEN50060            Research Techniques Space Eng    MME\n",
       "521  MEEN50070                    Industrial Research I    MME\n",
       "522  MEEN50080                   Industrial Research II    MME\n",
       "523  MEEN50090                  Industrial Research III    MME\n",
       "\n",
       "[524 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_raw=Path.Path(\"Datasets\")\n",
    "\n",
    "moduleCodes= dir_raw / \"MODULES.csv\"\n",
    "\n",
    "modules=pd.read_csv(moduleCodes)\n",
    "\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b852b57",
   "metadata": {},
   "source": [
    "The module descriptor scraper pulls all module descriptor information from the UCD module website. This includes information such as who runs the module, and importantly for our analysis, the number of credits for each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98326584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_descriptor_scraper(url, level=None, school=None):\n",
    "    #url= \"https://hub.ucd.ie/usis/!W_HU_MENU.P_PUBLISH?p_tag=MODULE&MODULE=\" + modules.iloc[0][\"Code\"]\n",
    "\n",
    "    request=requests.get(url)\n",
    "    soup=BeautifulSoup(request.content, 'html.parser')\n",
    "\n",
    "#print(soup)\n",
    "#Create all_h1_tags as empty list\n",
    "    descriptor_list={}\n",
    "\n",
    "# Set all_h1_tags to all h1 tags of the soup\n",
    "    for element in soup.select('dl'):\n",
    "        credit_list=element.text\n",
    "        for items in zip(soup.select('dt'), soup.select('dd')):\n",
    "            #print(items[0].text + \" \" + items[1].text)\n",
    "            descriptor_list[items[0].text]=items[1].text\n",
    "        #descriptor_item.append(items[1])\n",
    "        \n",
    "#print(\"%d , %d\" %(len(descriptor_type),len(descriptor_item)))\n",
    "\n",
    "    \n",
    "    module_descriptor=pd.Series(descriptor_list)\n",
    "    module_descriptor[\"Credits:\"]=pd.to_numeric(module_descriptor[\"Credits:\"], errors='coerce')\n",
    "    #print(module_descriptor)\n",
    "#print(element)\n",
    "\n",
    "    filtered=False\n",
    "    \n",
    "    #If filters exist, check that the module is not filtered out\n",
    "    if (level != None):\n",
    "        filtered= (pd.to_numeric(module_descriptor[\"Level:\"].split('(')[0], errors='ignore') != level)\n",
    "                   \n",
    "    #If it wasn't filtered out by level, check if it is filtered out by school\n",
    "    if (filtered == False) and (school != None):\n",
    "        filtered = (module_descriptor[\"School:\"] != school)\n",
    "                   \n",
    "\n",
    "    #if (filtered ==False) and (codeList != None):\n",
    "     #   if codeList.find(code) != -1:\n",
    "      #      print(\"%s is in the code list\" %code)\n",
    "       #else:\n",
    "        #    filtered=True\n",
    "\n",
    "    return module_descriptor, filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb159fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This asserts that the filter works correctly\n",
    "def assert_filtered(module_descriptors, level=None, school=None):\n",
    "    all_descriptors=pd.concat(module_descriptors)\n",
    "    \n",
    "    if level !=None:\n",
    "        assert (all_descriptors[\"Level:\"].nunique() == 1)\n",
    "    if school != None:\n",
    "        assert (all_descriptors[\"School:\"].nunique() == 1)\n",
    "        \n",
    "    print(all_descriptors[\"School:\"].unique())\n",
    "    return all_descriptors[\"School:\"].nunique(), all_descriptors[\"Level:\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7516c8",
   "metadata": {},
   "source": [
    "The below code collects all module assessment and module descriptor information into two lists. It also creates a \"Scaled % of Final Grade\" column in the asssessment table. This weights the assessment based on the number of credits the module has overall. In this way, the median and normal amount of credits, 5.0, has assessments weighting that add up to 100%. Those above and below are given assessment weightings that scale with how much more or less they are worth then a normal module - a 10 credit module will have assessments that add up to 200%, because they are worth twice the amount as a normal module.\n",
    "\n",
    "Error module details are stored for inspection later, to see why they occurred. The code continues on even if errors occur, after having stored these details it simply proceeds to the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93e1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_module_files(module_assessments, module_descriptors, level, school):\n",
    "    #The directory to save outputs to\n",
    "    dir_output=Path.Path(\"ModuleInformation\")\n",
    "    dir_output.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    #filenames={module_assessments: \"assessments\", module_descriptors:\"descriptors\"}\n",
    "    subdirectory=\"\"\n",
    "    #Save the file in its desired format\n",
    "    if level != None:\n",
    "        subdirectory+=\"Level=%d\" %(level)\n",
    "        \n",
    "    if school != None:\n",
    "        subdirectory+=\"_School=\"+school.replace(\" \", \"-\")\n",
    "    \n",
    "    #if the modules have been filtered, and thus belong in a sub directory, make that directory\n",
    "    if len(subdirectory) > 0:\n",
    "        dir_output=dir_output / subdirectory\n",
    "        dir_output.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    #Save our two module detail files\n",
    "    with open(dir_output / \"assessments.json\", 'w') as outfile:\n",
    "        if len(module_assessments) > 2:\n",
    "            module_assessments=pd.concat(module_assessments, ignore_index=True)\n",
    "            #print(module_assessments)\n",
    "        print(\"saving to %s\" % dir_output)\n",
    "        outfile.write(module_assessments.to_json())\n",
    "        \n",
    "    with open(dir_output / \"descriptors.json\", 'w') as outfile:\n",
    "        print(\"saving to %s\" % dir_output)\n",
    "        if len(module_descriptors) > 2:\n",
    "            module_descriptors=pd.DataFrame(module_descriptors)\n",
    "        outfile.write(module_descriptors.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a910083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This functiom will allow school and year functions to be placed on it\n",
    "def collector(codeList=None, level=None, school=None):\n",
    "    #This stores module information\n",
    "    module_assessments=[]\n",
    "    module_descriptors=[]\n",
    "\n",
    "    #This stores error module information\n",
    "    error_modules=[]\n",
    "    error_module_descriptors=[]\n",
    "\n",
    "    for i in modules.iloc:\n",
    "        print(\".\",end=\"\")\n",
    "        \n",
    "        #Check that the code is allowed \n",
    "        if codeList !=None:\n",
    "            if codeList.find(i[\"Code\"]) != -1:\n",
    "                print(\"%s is in the code list\" %i[\"Code\"])\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        url= \"https://hub.ucd.ie/usis/!W_HU_MENU.P_PUBLISH?p_tag=MODULE&MODULE=\" + i[\"Code\"]\n",
    "\n",
    "        #Get the module descriptor\n",
    "        descriptor, filtered=module_descriptor_scraper(url, level=level, school=school)\n",
    "        #If the module is in violation of the filters, continue to the next without saving\n",
    "        if filtered==True:\n",
    "            continue\n",
    "        #Use pandas to read in the asssessment html tables too\n",
    "        table=pd.read_html(url, match=\"Description\")\n",
    "        \n",
    "        #print(descriptor)\n",
    "        #Get the first table, and turn it into a dataframe\n",
    "        df=pd.DataFrame(table[0])\n",
    "        df[\"Assessment Type\"] = df['Description'].str.split(':').str[0]\n",
    "        try:\n",
    "            df[\"Scaled % of Final Grade\"]= df['% of Final Grade'].apply(lambda x: x * (descriptor[\"Credits:\"]/5.0))\n",
    "        except:\n",
    "            print(\"\\nERROR MODULE DETECTED.\")\n",
    "            #print(df[\"% of Final Grade\"])\n",
    "            #print(descriptor[\"Credits:\"])\n",
    "            print(\"Module may need to be inspected, saving information as an error module and continuing without it\")\n",
    "        \n",
    "            error_modules.append(df)\n",
    "            error_module_descriptors.append(descriptor)\n",
    "            #Continue after noting and saving the error\n",
    "            continue\n",
    "        \n",
    "        #Append the dataframe to the module assessments list\n",
    "        module_assessments.append(df)\n",
    "        module_descriptors.append(descriptor)\n",
    "    \n",
    "    #This asserts that the filters were properly imposed, if imposed at all\n",
    "    num_schools, num_levels=assert_filtered(module_descriptors, level, school)\n",
    "\n",
    "    print(\"\\nFINISHED, SCRAPED DETAILS ON %d MODULES, OVER %d SCHOOLS AND %d LEVELS\" \\\n",
    "          %(len(module_assessments), num_schools, num_levels))\n",
    "    \n",
    "    #Save the output files\n",
    "    save_module_files(module_assessments, module_descriptors, level, school)\n",
    "    \n",
    "    return module_assessments, module_descriptors, error_modules, error_module_descriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c18e430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Run the above function in its base form\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m module_assessments, module_descriptors, error_modules, error_module_descriptors\u001b[38;5;241m=\u001b[39m\u001b[43mcollector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m, in \u001b[0;36mcollector\u001b[1;34m(codeList, level, school)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#Check that the code is allowed \u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcodeList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is in the code list\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39mi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "#Run the above function in its base form\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreCodes= dir_raw / \"UCD_EngArch_Mech_UG_Modules.xlsx\"\n",
    "\n",
    "coreModules=pd.read_excel(coreCodes, header=None)\n",
    "\n",
    "coreList=coreModules.values.tolist()\n",
    "\n",
    "x=list(map(str,coreList))\n",
    "coreModules=\"-\".join(x)\n",
    "\n",
    "print(coreModules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef51058",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(codeList=coreModules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the collector function to only collect level 1 modules in the college of Engineering and Architecture\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143861bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the collector function to only collect level 1 modules in the college of Engineering and Architecture\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the collector function to only collect level 1 modules in the college of Engineering and Architecture\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a048019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the collector function to only collect level 1 modules in the college of Engineering and Architecture\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb466c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the collector function to only collect level 1 modules in the college of Engineering and Architecture\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(level=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the collector function to only collect level 1 modules in the college of Engineering and Architecture\n",
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(school=\"Mechanical & Materials Eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(school=\"Civil Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfeb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(school=\"Chem & Bioprocess Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(school=\"Biosystems & Food Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc77435",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(school=\"Architecture, Plan & Env Pol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace211cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_assessments, module_descriptors, error_modules, error_module_descriptors=collector(school=\"Electrical & Electronic Eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the error modules just in case\n",
    "for i, error in enumerate(zip(error_modules, error_module_descriptors)):\n",
    "    print(\"********ERROR COUNT %d*********\" %i)\n",
    "    print(error[0])\n",
    "    print(error[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf56b77",
   "metadata": {},
   "source": [
    "Next we combine all the modules assessment information together, ready for later aggregation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggreg_modules=pd.concat(module_assessments)\n",
    "\n",
    "aggreg_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessments=aggreg_modules[[\"Assessment Type\", \"% of Final Grade\"]]\n",
    "\n",
    "#This is the dataset cleaning, so that they are ready for presentation\n",
    "assessments[\"% of Final Grade\"]=pd.to_numeric(assessments[\"% of Final Grade\"], errors='coerce')\n",
    "assessments=assessments.replace(\"Multiple Choice Questionnaire (Short)\", \"Multiple Choice Questionnaire\")\n",
    "assessments=assessments.dropna()\n",
    "assessments[\"Assessment Type\"]=assessments[\"Assessment Type\"].astype(\"category\")\n",
    "\n",
    "assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58981d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56725e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assessments=assessments.replace(\"Multiple Choice Questionnaire (Short)\", \"Multiple Choice Questionnaire\")\n",
    "assessments[\"Assessment Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessments[\"Assessment Type\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assessments = assessments.drop(\"No yet recorded.\")\n",
    "assessment_average=assessments.groupby(by=\"Assessment Type\", as_index=False).mean()\n",
    "\n",
    "assessment_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_averages=assessment_average.sort_values(\"% of Final Grade\", ascending=False)\n",
    "\n",
    "sorted_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax=plt.subplots( figsize=(15, 10))\n",
    "\n",
    "#barWidth=0.25\n",
    "colormap={\"Essay\": \"gold\", \"Assignment\": \"gold\", \"Examination\": \"mediumseagreen\", \"Attendance\": \"mediumseagreen\", \\\n",
    "          \"Class Test\":\"mediumseagreen\", \"Continuous Assessment\": \"gold\", \"Fieldwork\": \"mediumseagreen\", \"Group Project\": \"gold\",\\\n",
    "         \"Journal\": \"gold\", \"Lab Report\" : \"mediumseagreen\", \"Multiple Choice Questionnaire (MCQ)\": \"mediumseagreen\", \\\n",
    "          \"Oral Examination\" : \"mediumseagreen\", \"Portfolio\": \"gold\", \"Practical Examination\": \"mediumseagreen\",\\\n",
    "          \"Presentation\":\"mediumseagreen\", \"Project\": \"gold\", \"Seminar\": \"mediumseagreen\",\\\n",
    "          \"Studio Examination\": \"mediumseagreen\", \"Assessments worth <2%\": \"mediumseagreen\"}\n",
    "\n",
    "# Make the plot\n",
    "ax.bar(sorted_averages[\"Assessment Type\"], sorted_averages[\"% of Final Grade\"], edgecolor=\"grey\", color=[\"mediumseagreen\", \"gold\", \\\n",
    "\"gold\", \"mediumseagreen\", \"mediumseagreen\", \"gold\", \"gold\",  \"mediumseagreen\", \"gold\", \"gold\", \"gold\", \"mediumseagreen\",\\\n",
    "                                                                                       \"mediumseagreen\", \"mediumseagreen\", \\\n",
    "                                                \"mediumseagreen\", \"gold\", \"mediumseagreen\", \"mediumseagreen\"] )\n",
    "\n",
    "\n",
    "#Set the options for the axes\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "ax.tick_params(axis='x', rotation=90, labelsize=14)\n",
    "#ax.legend(fontsize=20)\n",
    "ax.set_xlabel(\"Assessment Type\", fontsize=18)\n",
    "ax.set_ylabel(\"% of Final Grade\",fontsize=18)\n",
    "#Add the date lines for context\n",
    "ax.set_title(\"Average Module Percentage When Assessment Type is Used\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_total=assessments.groupby(by=\"Assessment Type\", as_index=False).sum()\n",
    " \n",
    "assessment_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total=assessment_total[\"% of Final Grade\"].sum()\n",
    "\n",
    "assessment_total[\"% of Assessment\"]=assessment_total[\"% of Final Grade\"].apply(lambda x: x/total)\n",
    "assessment_total[\"Assessment Type\"]=assessment_total[\"Assessment Type\"].cat.add_categories(\"Assessments worth <2%\")\n",
    "assessment_total.loc[assessment_total[\"% of Assessment\"] < 0.02, \"Assessment Type\"] = \"Assessments worth <2%\"\n",
    "\n",
    "assessment_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_total[\"Assessment Type\"]= assessment_total[\"Assessment Type\"].cat.remove_categories([\"Fieldwork\", \"Journal\", \\\n",
    "                                                                             \"Attendance\", \"Oral Examination\", \\\n",
    "                                                \"Practical Examination\", \"Seminar\", \"Studio Examination\",\\\n",
    "                                                                                             \"Multiple Choice Questionnaire\"])\n",
    "\n",
    "assessment_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39163da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_asses=assessment_total.groupby(by=\"Assessment Type\").sum()\n",
    "\n",
    "pie_assessment=filtered_asses[\"% of Assessment\"]\n",
    "\n",
    "sorted_totals=pie_assessment.sort_values(ascending=False)\n",
    "\n",
    "sorted_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(15,12))\n",
    "\n",
    "#exploded=[0.03, 0, 0.03, 0.03, 0, 0.03, 0.03, 0.03, 0, 0, 0]\n",
    "ax.pie(sorted_totals, wedgeprops = { 'linewidth' : 0.5, 'edgecolor' : 'grey' }, \\\n",
    "       autopct=\"%1.1f%%\", labels=sorted_totals.index, colors=[\"gold\",\"mediumseagreen\", \\\n",
    "\"gold\", \"gold\", \"mediumseagreen\",  \"gold\", \"gold\", \"gold\", \"mediumseagreen\",\\\n",
    "                                                              \"mediumseagreen\", \"mediumseagreen\", \"mediumseagreen\"])\n",
    "\n",
    "#my_circle=ax.Circle( (0,0), 0.7, color='white')\n",
    "#p=ax.gcf()\n",
    "\n",
    "ax.set_title(\"Assessment type as a Percentage of Module Assessments\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
