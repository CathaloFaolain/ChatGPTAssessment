{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ba74d6",
   "metadata": {},
   "source": [
    "# Exploration : No Exam Modules\n",
    "Our discussion and data exploration led to the discovery that 350 modules have no exam at all in their assessment. This is over 60% of the entire college of Enigineering and Architecture, and are likely to be at a much greater risk of ChatGPT then others. This notebook is for finding out which groups exist within this subset of data, and assessing their threat level. \n",
    "\n",
    "First we will need some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9dac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pathlib as Path\n",
    "import html5lib\n",
    "import json\n",
    "import matplotlib.ticker as mtick\n",
    "import plotly.express as px\n",
    "import sklearn \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff52615",
   "metadata": {},
   "source": [
    "We will need a file finder for this, so we will copy that over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This finds files that were saved by the Module Scraper Code\n",
    "def file_finder(school=None, level=None, givenList=None, filename=None, module=None):\n",
    "    #Set the path to the overall directory with our input files\n",
    "    dir_raw=Path.Path(\"ModuleInformation\")\n",
    "    \n",
    "    #This locates the subdirectory where files by school, level or list can be found\n",
    "    subdirectory=\"\"\n",
    "    #Set the subdirectory \n",
    "    if level != None:\n",
    "        subdirectory+= \"Level=%d\" %(level)\n",
    "    if school != None:\n",
    "        subdirectory+= \"_School=\"+school.replace(\" \", \"-\")\n",
    "    if filename != None:\n",
    "        subdirectory = filename\n",
    "    if module != None:\n",
    "        subdirectory = (\"IndividualModules/%s\" %module)\n",
    "        \n",
    "    #If a subdirectory has indeed been set, change the path to reflect this\n",
    "    if len(subdirectory) > 0:\n",
    "        dir_raw =dir_raw / subdirectory\n",
    "        \n",
    "\n",
    "    #Read the files for the assessment and descriptors in, closing the file immediately after\n",
    "    with open(dir_raw / \"assessments.json\", 'r') as infile:\n",
    "        print(\"Reading from %s\" % dir_raw)\n",
    "        if module != None:\n",
    "            assessments=pd.read_json(infile, orient=\"columns\")\n",
    "        else:\n",
    "            assessments=pd.read_json(infile)\n",
    "    with open(dir_raw / \"descriptors.json\", 'r') as infile:\n",
    "        print(\"Reading from %s\" % dir_raw)\n",
    "        if module != None:\n",
    "            descriptors=pd.read_json(infile, typ=\"series\")\n",
    "        else:\n",
    "            descriptors=pd.read_json(infile)\n",
    "    \n",
    "    assessments[\"Level\"]=assessments[\"Level\"].apply(lambda x: pd.to_numeric(x.split('(')[0], errors='ignore'))\n",
    "    #This is the dataset cleaning, so that they are ready for presentation\n",
    "    assessments[\"% of Final Grade\"]=pd.to_numeric(assessments[\"% of Final Grade\"], errors='coerce')\n",
    "    assessments=assessments.replace(\"Multiple Choice Questionnaire (Short)\", \"Multiple Choice Questionnaire\")\n",
    "    assessments[\"Assessment Type\"]=assessments[\"Assessment Type\"].astype(\"category\")\n",
    "    #assessments[\"Stage\"]=assessments[\"Stage\"].replace(\"M\", 4)\n",
    "    assessments[\"Student Credits\"]=((assessments[\"Scaled % of Final Grade\"]/100)*5)*assessments[\"Enrolled Students 22/23\"]\n",
    "    assessments[\"Assessment Credits\"]=((assessments[\"Scaled % of Final Grade\"]/100)*5)\n",
    "    #Return the desired assessment and description information\n",
    "    return assessments, descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89784c53",
   "metadata": {},
   "source": [
    "Print out the assessments to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the file finder function \n",
    "assessments, descriptors = file_finder()\n",
    "\n",
    "assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6db91",
   "metadata": {},
   "source": [
    "This is an important dict that shows where module assessment types are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_type={\"Assignment\" :\"At home\", \\\n",
    "                \"Attendance\": \"In person\", \\\n",
    "                \"Class Test\" : \"In person\", \\\n",
    "                \"Continuous Assessment\": \"At home\", \\\n",
    "               \"Essay\": \"At home\", \\\n",
    "                \"Examination\": \"In person\", \\\n",
    "                \"Fieldwork\": \"In person\", \\\n",
    "                \"Group Project\": \"Blended\", \\\n",
    "                \"Journal\": \"Blended\",\\\n",
    "               \"Lab Report\": \"Blended\", \\\n",
    "                \"Multiple Choice Questionnaire\": \"Blended\", \\\n",
    "                \"Oral Examination\": \"In person\", \\\n",
    "               \"Portfolio\" : \"Blended\",  \\\n",
    "                \"Practical Examination\": \"In person\", \\\n",
    "                \"Presentation\" : \"In person\", \\\n",
    "                \"Project\": \"At home\", \\\n",
    "               \"Seminar\": \"In person\", \\\n",
    "               \"Studio Examination\" : \"In person\",\\\n",
    "               \"Assessments worth <2%\": \"Unknown\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1aa7c2",
   "metadata": {},
   "source": [
    "We will need to pivot the assessments table and set up the module analysis dataframe. Next we will save this, as a very important dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_analysis=assessments.pivot_table(\"% of Final Grade\", \\\n",
    "                               [\"School\", \"Level\", \"Module Code\", \"Enrolled Students 22/23\", \"Credits\"], \\\n",
    "                               \"Assessment Type\", observed=True, fill_value=0)\n",
    "module_analysis.reset_index( inplace=True)\n",
    "#Reset the index and make a new index of all the columns that should make a row unique\n",
    "module_analysis.set_index(\"Module Code\", inplace=True)\n",
    "\n",
    "module_analysis[\"Student Credits\"]=module_analysis[\"Enrolled Students 22/23\"]*module_analysis[\"Credits\"]\n",
    "\n",
    "work_type={\"Assignment\" :\"At home\", \\\n",
    "                \"Attendance\": \"In person\", \\\n",
    "                \"Class Test\" : \"In person\", \\\n",
    "                \"Continuous Assessment\": \"At home\", \\\n",
    "               \"Essay\": \"At home\", \\\n",
    "                \"Examination\": \"In person\", \\\n",
    "                \"Fieldwork\": \"In person\", \\\n",
    "                \"Group Project\": \"Blended\", \\\n",
    "                \"Journal\": \"Blended\",\\\n",
    "               \"Lab Report\": \"Blended\", \\\n",
    "                \"Multiple Choice Questionnaire\": \"Blended\", \\\n",
    "                \"Oral Examination\": \"In person\", \\\n",
    "               \"Portfolio\" : \"Blended\",  \\\n",
    "                \"Practical Examination\": \"In person\", \\\n",
    "                \"Presentation\" : \"In person\", \\\n",
    "                \"Project\": \"At home\", \\\n",
    "               \"Seminar\": \"In person\", \\\n",
    "               \"Studio Examination\" : \"In person\",\\\n",
    "               \"Assessments worth <2%\": \"Unknown\"}\n",
    "\n",
    "module_analysis[\"In Person Percentage\"]=module_analysis[\"Attendance\"]+module_analysis[\"Class Test\"]+\\\n",
    "module_analysis[\"Examination\"]+module_analysis[\"Fieldwork\"]+module_analysis[\"Oral Examination\"]\\\n",
    "+module_analysis[\"Practical Examination\"]+module_analysis[\"Presentation\"]+module_analysis[\"Seminar\"]+\\\n",
    "module_analysis[\"Studio Examination\"]\n",
    "\n",
    "module_analysis[\"At Home Percentage\"]=module_analysis[\"Assignment\"]+module_analysis[\"Continuous Assessment\"]+\\\n",
    "module_analysis[\"Essay\"]+module_analysis[\"Project\"]\n",
    "\n",
    "module_analysis[\"Blended Percentage\"]=module_analysis[\"Group Project\"]+module_analysis[\"Journal\"]+\\\n",
    "module_analysis[\"Lab Report\"]+module_analysis[\"Multiple Choice Questionnaire\"]+module_analysis[\"Portfolio\"]\n",
    "module_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
